{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe8c500-00d7-435a-a1b4-50c5136044a5",
   "metadata": {},
   "source": [
    "# Atari Behavior Cloning\n",
    "In this example we use a special form of imitation learning (IL) called behavior cloning for learning a policy to play the Atari game \"Breakout\". The agent witll be an NCP using a CfC as recurrent NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc0d19-14e2-4e59-a377-417cae1bd073",
   "metadata": {},
   "source": [
    "## Setup and Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24285773-2f5c-4416-8e93-838eeb687455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ncps in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: torch in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (2.2.1)\n",
      "Collecting ale-py==0.7.4\n",
      "  Downloading ale_py-0.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting ray[rllib]==2.1.0\n",
      "  Downloading ray-2.1.0-cp310-cp310-manylinux2014_x86_64.whl (58.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting gym[accept-rom-license,atari]==0.23.1\n",
      "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ale-py==0.7.4) (1.26.4)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: attrs in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (23.2.0)\n",
      "Collecting virtualenv>=20.0.24\n",
      "  Downloading virtualenv-20.26.2-py3-none-any.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (23.2)\n",
      "Requirement already satisfied: aiosignal in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (1.3.1)\n",
      "Requirement already satisfied: filelock in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (3.13.1)\n",
      "Requirement already satisfied: requests in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (2.31.0)\n",
      "Requirement already satisfied: frozenlist in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (1.4.1)\n",
      "Collecting click<=8.0.4,>=7.0\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (4.25.3)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (1.62.0)\n",
      "Requirement already satisfied: jsonschema in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (4.21.1)\n",
      "Collecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.1/385.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (6.0.1)\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (2.2.1)\n",
      "Collecting tensorboardX>=1.9\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (1.13.0)\n",
      "Collecting lz4\n",
      "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.4.3 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (3.8.3)\n",
      "Collecting dm-tree\n",
      "  Using cached dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "Requirement already satisfied: tabulate in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ray[rllib]==2.1.0) (0.9.0)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting autorom[accept-rom-license]~=0.4.2\n",
      "  Using cached AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: future in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from ncps) (1.0.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: jinja2 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: networkx in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: tqdm in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.23.1) (4.66.2)\n",
      "Collecting AutoROM.accept-rom-license\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.3.1 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.1.0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.1.0) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.1.0) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.1.0) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.1.0) (4.49.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.1.0) (10.2.0)\n",
      "Collecting distlib<1,>=0.3.7\n",
      "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs<5,>=3.9.1 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray[rllib]==2.1.0) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from jsonschema->ray[rllib]==2.1.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from jsonschema->ray[rllib]==2.1.0) (0.35.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from jsonschema->ray[rllib]==2.1.0) (0.18.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from pandas->ray[rllib]==2.1.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from pandas->ray[rllib]==2.1.0) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from requests->ray[rllib]==2.1.0) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from requests->ray[rllib]==2.1.0) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from requests->ray[rllib]==2.1.0) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from requests->ray[rllib]==2.1.0) (3.6)\n",
      "Collecting imageio>=2.33\n",
      "  Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2024.5.10-py3-none-any.whl (225 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lazy-loader>=0.4\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.4.3->ray[rllib]==2.1.0) (1.16.0)\n",
      "Building wheels for collected packages: gym, AutoROM.accept-rom-license\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.23.1-py3-none-any.whl size=701346 sha256=cab31d93edfc50b25a5bbf0b2f33a585323b24526600eef6a9b165030b0f1156\n",
      "  Stored in directory: /home/simon/.cache/pip/wheels/1a/00/fb/fe5cf2860fb9b7bc860e28f00095a1f42c7b726dd6f42d1acc\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=bf7ad31da6c137acda8f07dfadbd41e289afa8dd7cb73110be027950ca7ef13c\n",
      "  Stored in directory: /home/simon/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
      "Successfully built gym AutoROM.accept-rom-license\n",
      "Installing collected packages: gym-notices, dm-tree, distlib, virtualenv, tifffile, tensorboardX, msgpack, lz4, lazy-loader, importlib-resources, imageio, cloudpickle, click, scikit-image, gym, AutoROM.accept-rom-license, autorom, ale-py, ray\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.7.4 autorom-0.4.2 click-8.0.4 cloudpickle-3.0.0 distlib-0.3.8 dm-tree-0.1.8 gym-0.23.1 gym-notices-0.0.8 imageio-2.34.1 importlib-resources-6.4.0 lazy-loader-0.4 lz4-4.3.3 msgpack-1.0.8 ray-2.1.0 scikit-image-0.23.2 tensorboardX-2.6.2.2 tifffile-2024.5.10 virtualenv-20.26.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ncps torch \"ale-py==0.7.4\" \"ray[rllib]==2.1.0\" \"gym[atari,accept-rom-license]==0.23.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fbbe04-a23e-40a2-973d-0918ecec45a1",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "The model consists of a convolutional block (for feature extraction from the image), followed by a CfC recurrent neural network (keeping track of the state), and a final linear layer (deriving actions from the state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f458732-a171-43ea-ad58-7810f4293b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=5, padding=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=128)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=5, padding=2, stride=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = x.mean((-1, -2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055b6411-4869-4ccc-ac3a-5e46c26da8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncps.torch import CfC\n",
    "\n",
    "class ConvCfC(nn.Module):\n",
    "    def __init__(self, n_actions):\n",
    "        super().__init__()\n",
    "        self.conv_block = ConvBlock()\n",
    "        self.rnn = CfC(input_size=256, units=64, batch_first=True, proj_size=n_actions)\n",
    "\n",
    "    def forward(self, x, hx=None):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        # Merge batch and time dimension into a single one (because the Conv layers require this)\n",
    "        x = x.view(batch_size * seq_len, *x.shape[2:])\n",
    "        x = self.conv_block(x)\n",
    "        # Seperate time and batch dimension again\n",
    "        x = x.view(batch_size, seq_len, *x.shape[1:])\n",
    "        x, hx = self.rnn(x, hx) # hx is the hidden state of the RNN\n",
    "        return x, hx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da54ee-ec20-408e-8b50-48dc07cd3f00",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "Now we define the Atari environment and the dataset. For this we have to wrap the environemnt with some helper functions, which apply the following transformations:\n",
    "- Downscales the Atari frames to 84-by-84 pixels\n",
    "- Converts the frames to grayscale\n",
    "- Stacks 4 consecutive frames into a single observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3b1e4a-eb01-4daf-b801-9976ad2edf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import packaging\n",
      "/home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/ray/tune/logger/tensorboardx.py:35: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  VALID_NP_HPARAMS = (np.bool8, np.float32, np.float64, np.int32, np.int64)\n",
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n",
      "/home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/gym/utils/seeding.py:138: DeprecationWarning: \u001b[33mWARN: Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "/home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/gym/utils/seeding.py:175: DeprecationWarning: \u001b[33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "2024-05-24 10:55:36,991\tWARNING deprecation.py:47 -- DeprecationWarning: `FrameStack` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ale_py\n",
    "from ray.rllib.env.wrappers.atari_wrappers import wrap_deepmind\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"ALE/Breakout-v5\")\n",
    "env = wrap_deepmind(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af9b133-6c46-4541-b1dc-be6be3bea45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from ncps.datasets.torch import AtariCloningDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_ds = AtariCloningDataset(\"breakout\", split=\"train\")\n",
    "val_ds = AtariCloningDataset(\"breakout\", split=\"val\")\n",
    "trainloader = DataLoader(train_ds, batch_size=32, num_workers=4, shuffle=True)\n",
    "valloader = DataLoader(val_ds, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf947bff-be99-477c-8227-aedd5a49e890",
   "metadata": {},
   "source": [
    "## Running the model in a closed-loop\n",
    "Next, we have to define the code for applying the model in a continuous control loop with the environment. Important things to take care of are:\n",
    "1. Reset the RNN hidden states when a new episode starts in the Atari game\n",
    "2. Reshape the input frames to have an extra batch and time dimension of size 1 as the network accepts only batches of sequences instead of single frames\n",
    "3. Pass the current hidden state together with the observation as input, and unpack the prediciton and next hidden state from the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e3a6f3-50b8-4232-8ef3-9398318ad9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_closed_loop(model, env, num_episodes=None):\n",
    "    obs = env.reset()\n",
    "    device = next(model.parameters()).device\n",
    "    hx = None # Initialize hidden state of the RNN\n",
    "    returns = []\n",
    "    total_reward = 0\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            # PyTorch requires channel first image -> tranpose data\n",
    "            obs = np.tranpose(obs, [2, 0, 1]).astype(np.float32) / 255.0\n",
    "            obs = torch.from_numpy(obs).unsqueeze(0).unsqueeze(0).to(device) # create tensor, add time and batch dim, move to device\n",
    "            pred, hx = model(obs, hx)\n",
    "            # remove time and batch dimension -> then argmax\n",
    "            action = pred.squeeze(0).squeeze(0).argmax().item()\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            total_reward += r\n",
    "            if done:\n",
    "                obs = env.reset() # reset the environment\n",
    "                hx = None # reset the hidden state\n",
    "                returns.append(total_reward)\n",
    "                total_reward = 0 # reset reward\n",
    "                if num_episodes is not None:\n",
    "                    num_episodes -= 1 # count down the number of episodes\n",
    "                    if num_episodes == 0:\n",
    "                        return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d8ede5-3d54-425f-9100-7daed13f5eac",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "Let's write our training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beae5a8e-6f83-49c9-9734-3ab0b8ee88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, trainloader):\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(total=len(trainloader))\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs, hx = model(inputs)\n",
    "        labels = labels.view(-1, *labels.shape[2:])  # flatten\n",
    "        outputs = outputs.reshape(-1, *outputs.shape[2:])  # flatten\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_description(f\"loss={running_loss / (i + 1):0.4g}\")\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "def validate(model, valloader):\n",
    "    losses, accs = [], []\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs, _ = model(inputs)\n",
    "            outputs = outputs.reshape(-1, *outputs.shape[2:])\n",
    "            labels = labels.view(-1, *labels.shape[2:])\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = (outputs.argmax(-1) == labels).float().mean()\n",
    "            losses.append(loss.item())\n",
    "            accs.append(acc.item())\n",
    "    return np.mean(losses), np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e235c-68d6-4d41-920d-6f9c9204b5ff",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e1e904-9e54-4b16-8a97-b01e50138587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:42<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 201.19 MiB is free. Including non-PyTorch memory, this process has 1.04 GiB memory in use. Of the allocated memory 1005.83 MiB is allocated by PyTorch, and 14.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Evaluate model no the validation set\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, valloader)\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, criterion, optimizer, trainloader)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m outputs, hx \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mlabels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])  \u001b[38;5;66;03m# flatten\u001b[39;00m\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39moutputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])  \u001b[38;5;66;03m# flatten\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36mConvCfC.forward\u001b[0;34m(self, x, hx)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Merge batch and time dimension into a single one (because the Conv layers require this)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size \u001b[38;5;241m*\u001b[39m seq_len, \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m---> 14\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Seperate time and batch dimension again\u001b[39;00m\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, seq_len, \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn4(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x)))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/torch/nn/functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 201.19 MiB is free. Including non-PyTorch memory, this process has 1.04 GiB memory in use. Of the allocated memory 1005.83 MiB is allocated by PyTorch, and 14.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvCfC(n_actions=env.action_space.n).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_one_epoch(model, criterion, optimizer, trainloader)\n",
    "\n",
    "    # Evaluate model no the validation set\n",
    "    val_loss, val_acc = validate(model, valloader)\n",
    "    print(f\"Epoch {epoch+1}, val_loss={val_loss:0.4g}, val_acc={100*val_acc:0.2f}%\")\n",
    "\n",
    "    # Apply model in closed-loop environment\n",
    "    returns = run_closed_loop(model, env, num_episodes=10)\n",
    "    print(f\"Mean return {np.mean(returns)} (n={len(returns)})\")\n",
    "\n",
    "# Display how our model plays the game\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"human\")\n",
    "env = wrap_deepmind(env)\n",
    "run_closed_loop(model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8caf64-bbdd-4b1c-bb97-aa9b61d693db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/gym/utils/seeding.py:138: DeprecationWarning: \u001b[33mWARN: Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "/home/simon/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/gym/utils/seeding.py:175: DeprecationWarning: \u001b[33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'tranpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALE/Breakout-v5\u001b[39m\u001b[38;5;124m\"\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m wrap_deepmind(env)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrun_closed_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mrun_closed_loop\u001b[0;34m(model, env, num_episodes)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# PyTorch requires channel first image -> tranpose data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m         obs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranpose\u001b[49m(obs, [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m     11\u001b[0m         obs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(obs)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# create tensor, add time and batch dim, move to device\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         pred, hx \u001b[38;5;241m=\u001b[39m model(obs, hx)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/pytorch_tutorials/lib/python3.10/site-packages/numpy/__init__.py:333\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'tranpose'"
     ]
    }
   ],
   "source": [
    "# Display how our model plays the game\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"human\")\n",
    "env = wrap_deepmind(env)\n",
    "run_closed_loop(model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f887ee5-8f3f-47ae-8b21-6070d1c7e9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
